Things done:
- Implemented Flash attention 2 forward pass
- Completed Umar Sensei's video for fwd pass till theory
- Learned about template in CUDA C

Next steps:
- Verify with torch implementation
- Optimize for numerical stability (Kahan compensation) & memory efficiency (__half)
